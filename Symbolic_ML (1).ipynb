{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evL4I7OUfS85",
        "outputId": "deb3ae4b-6122-4d0d-b719-6f2cf0042fff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([4, 10]), Target shape: torch.Size([4, 10])\n",
            "Epoch 1, Loss: 93.42350115094867\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([4, 10]), Target shape: torch.Size([4, 10])\n",
            "Epoch 2, Loss: 52.22529983520508\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([4, 10]), Target shape: torch.Size([4, 10])\n",
            "Epoch 3, Loss: 33.88801165989467\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([4, 10]), Target shape: torch.Size([4, 10])\n",
            "Epoch 4, Loss: 27.90635245186942\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([4, 10]), Target shape: torch.Size([4, 10])\n",
            "Epoch 5, Loss: 25.396030153547013\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([4, 10]), Target shape: torch.Size([4, 10])\n",
            "Epoch 6, Loss: 24.16272517613002\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([4, 10]), Target shape: torch.Size([4, 10])\n",
            "Epoch 7, Loss: 22.187196459089005\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([4, 10]), Target shape: torch.Size([4, 10])\n",
            "Epoch 8, Loss: 20.86636870247977\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([4, 10]), Target shape: torch.Size([4, 10])\n",
            "Epoch 9, Loss: 19.031072071620397\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([4, 10]), Target shape: torch.Size([4, 10])\n",
            "Epoch 10, Loss: 17.77355166843959\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([4, 10]), Target shape: torch.Size([4, 10])\n",
            "Epoch 1, Loss: 91.61481693812779\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([4, 10]), Target shape: torch.Size([4, 10])\n",
            "Epoch 2, Loss: 64.4981302533831\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([4, 10]), Target shape: torch.Size([4, 10])\n",
            "Epoch 3, Loss: 44.87509972708566\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([4, 10]), Target shape: torch.Size([4, 10])\n",
            "Epoch 4, Loss: 33.69087246486119\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([4, 10]), Target shape: torch.Size([4, 10])\n",
            "Epoch 5, Loss: 25.732886723109655\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([4, 10]), Target shape: torch.Size([4, 10])\n",
            "Epoch 6, Loss: 21.132472446986608\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([4, 10]), Target shape: torch.Size([4, 10])\n",
            "Epoch 7, Loss: 16.517278262547084\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([4, 10]), Target shape: torch.Size([4, 10])\n",
            "Epoch 8, Loss: 12.687910897391182\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([4, 10]), Target shape: torch.Size([4, 10])\n",
            "Epoch 9, Loss: 8.477220467158727\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([16, 10]), Target shape: torch.Size([16, 10])\n",
            "Output shape: torch.Size([4, 10]), Target shape: torch.Size([4, 10])\n",
            "Epoch 10, Loss: 4.165062768118722\n"
          ]
        }
      ],
      "source": [
        "import sympy as sp\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "\n",
        "# === Step 1: Generate Functions and Their Taylor Expansions ===\n",
        "def generate_taylor_dataset(n_samples=100):\n",
        "    x = sp.Symbol('x')\n",
        "    functions = [sp.sin(x), sp.cos(x), sp.exp(x), sp.log(1 + x), x**2 + 3*x + 5]\n",
        "    dataset = []\n",
        "\n",
        "    for _ in range(n_samples):\n",
        "        func = random.choice(functions)\n",
        "        taylor_series = sp.series(func, x, 0, 5).removeO()\n",
        "        dataset.append((str(func), str(taylor_series)))\n",
        "\n",
        "    return dataset\n",
        "\n",
        "dataset = generate_taylor_dataset()\n",
        "\n",
        "# === Step 2: Tokenize the Dataset ===\n",
        "def tokenize_expression(expression):\n",
        "    tokens = list(expression.replace(\" \", \"\"))\n",
        "    return tokens\n",
        "\n",
        "all_tokens = set()\n",
        "for func, taylor in dataset:\n",
        "    all_tokens.update(tokenize_expression(func))\n",
        "    all_tokens.update(tokenize_expression(taylor))\n",
        "\n",
        "token_to_idx = {token: i for i, token in enumerate(sorted(all_tokens))}\n",
        "idx_to_token = {i: token for token, i in token_to_idx.items()}\n",
        "\n",
        "def encode_expression(expression, max_len=10):  # Ensure max_len matches LSTM output\n",
        "    encoded = [token_to_idx[token] for token in tokenize_expression(expression)]\n",
        "    return encoded[:max_len] + [0] * (max_len - len(encoded))\n",
        "\n",
        "data_encoded = [(encode_expression(func), encode_expression(taylor)) for func, taylor in dataset]\n",
        "\n",
        "# === Step 3: Prepare DataLoader for LSTM ===\n",
        "class TaylorDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.data[idx][0]), torch.tensor(self.data[idx][1])\n",
        "\n",
        "dataset = TaylorDataset(data_encoded)\n",
        "train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# === Step 4: LSTM Model ===\n",
        "class LSTMPredictor(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=32, hidden_dim=64, output_dim=10):  # output_dim = 10\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)  # Ensure output matches target size\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        _, (hidden, _) = self.lstm(x)\n",
        "        return self.fc(hidden[-1])  # Output: (batch_size, output_dim)\n",
        "\n",
        "vocab_size = len(token_to_idx)\n",
        "lstm_model = LSTMPredictor(vocab_size)\n",
        "optimizer = optim.Adam(lstm_model.parameters(), lr=0.01)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# === Step 5: Train LSTM ===\n",
        "def train_lstm(model, train_loader, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for inputs, targets in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            print(f\"Output shape: {outputs.shape}, Target shape: {targets.shape}\")  # Debugging\n",
        "\n",
        "            loss = criterion(outputs, targets.float())  # Ensure targets are float\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}\")\n",
        "\n",
        "train_lstm(lstm_model, train_loader)\n",
        "\n",
        "# === Step 6: Transformer Model ===\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=32, num_heads=2, hidden_dim=64, output_dim=10):  # output_dim = 10\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads)\n",
        "        self.transformer = nn.TransformerEncoder(self.encoder_layer, num_layers=2)\n",
        "        self.fc = nn.Linear(embed_dim, output_dim)  # Ensure output matches target size\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x).permute(1, 0, 2)  # Change shape for transformer\n",
        "        x = self.transformer(x)\n",
        "        x = x.mean(dim=0)  # Take mean over sequence length\n",
        "        return self.fc(x)  # Output: (batch_size, output_dim)\n",
        "\n",
        "transformer_model = TransformerModel(vocab_size)\n",
        "optimizer_trans = optim.Adam(transformer_model.parameters(), lr=0.01)\n",
        "\n",
        "# === Step 7: Train Transformer ===\n",
        "def train_transformer(model, train_loader, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for inputs, targets in train_loader:\n",
        "            optimizer_trans.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            print(f\"Output shape: {outputs.shape}, Target shape: {targets.shape}\")  # Debugging\n",
        "\n",
        "            loss = criterion(outputs, targets.float())  # Ensure targets are float\n",
        "            loss.backward()\n",
        "            optimizer_trans.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}\")\n",
        "\n",
        "train_transformer(transformer_model, train_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sympy as sp\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "\n",
        "# === Step 1: Generate Functions and Their Taylor Expansions ===\n",
        "def generate_taylor_dataset(n_samples=100):\n",
        "    x = sp.Symbol('x')\n",
        "    functions = [sp.sin(x), sp.cos(x), sp.exp(x), sp.log(1 + x), x**2 + 3*x + 5]\n",
        "    dataset = []\n",
        "\n",
        "    for _ in range(n_samples):\n",
        "        func = random.choice(functions)\n",
        "        taylor_series = sp.series(func, x, 0, 5).removeO()\n",
        "        dataset.append((str(func), str(taylor_series)))\n",
        "\n",
        "    return dataset\n",
        "\n",
        "dataset = generate_taylor_dataset()\n",
        "\n",
        "# === Step 2: Tokenize the Dataset ===\n",
        "def tokenize_expression(expression):\n",
        "    return list(expression.replace(\" \", \"\"))\n",
        "\n",
        "# Build vocabulary from dataset\n",
        "all_tokens = set()\n",
        "for func, taylor in dataset:\n",
        "    all_tokens.update(tokenize_expression(func))\n",
        "    all_tokens.update(tokenize_expression(taylor))\n",
        "\n",
        "token_to_idx = {token: i for i, token in enumerate(sorted(all_tokens))}\n",
        "idx_to_token = {i: token for token, i in token_to_idx.items()}\n",
        "\n",
        "# Convert expressions to numerical sequences\n",
        "def encode_expression(expression, max_len=10):\n",
        "    encoded = [token_to_idx[token] for token in tokenize_expression(expression)]\n",
        "    return encoded[:max_len] + [0] * (max_len - len(encoded))  # Pad/truncate to fixed length\n",
        "\n",
        "data_encoded = [(encode_expression(func), encode_expression(taylor)) for func, taylor in dataset]\n",
        "\n",
        "# === Step 3: Prepare DataLoader ===\n",
        "class TaylorDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_seq, target_seq = self.data[idx]\n",
        "        return torch.tensor(input_seq, dtype=torch.long), torch.tensor(target_seq[0], dtype=torch.long)\n",
        "        # Target is the first token of the Taylor expansion (classification task)\n",
        "\n",
        "dataset = TaylorDataset(data_encoded)\n",
        "train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# === Step 4: LSTM Model ===\n",
        "class LSTMPredictor(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=32, hidden_dim=64, output_dim=None):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)  # Predicts a token from vocabulary\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        _, (hidden, _) = self.lstm(x)\n",
        "        return self.fc(hidden[-1])\n",
        "\n",
        "vocab_size = len(token_to_idx)\n",
        "lstm_model = LSTMPredictor(vocab_size)\n",
        "optimizer = optim.Adam(lstm_model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# === Step 5: Training Function with Accuracy ===\n",
        "def train_lstm(model, train_loader, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "\n",
        "        for inputs, targets in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)  # Shape: [batch_size, vocab_size]\n",
        "\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Accuracy Calculation\n",
        "            predicted = torch.argmax(outputs, dim=1)  # Get predicted token indices\n",
        "            correct_predictions += (predicted == targets).sum().item()\n",
        "            total_predictions += targets.size(0)  # Use batch_size\n",
        "\n",
        "        accuracy = (correct_predictions / total_predictions) * 100\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "train_lstm(lstm_model, train_loader)\n",
        "\n",
        "# === Step 6: Transformer Model ===\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=32, num_heads=2, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads)\n",
        "        self.transformer = nn.TransformerEncoder(self.encoder_layer, num_layers=2)\n",
        "        self.fc = nn.Linear(embed_dim, vocab_size)  # Predicts a token from vocabulary\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x).permute(1, 0, 2)  # Change shape for transformer\n",
        "        x = self.transformer(x)\n",
        "        x = x.mean(dim=0)  # Take mean over sequence length\n",
        "        return self.fc(x)\n",
        "\n",
        "transformer_model = TransformerModel(vocab_size)\n",
        "optimizer_trans = optim.Adam(transformer_model.parameters(), lr=0.01)\n",
        "\n",
        "# === Step 7: Training Transformer with Accuracy ===\n",
        "def train_transformer(model, train_loader, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "\n",
        "        for inputs, targets in train_loader:\n",
        "            optimizer_trans.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer_trans.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Accuracy Calculation\n",
        "            predicted = torch.argmax(outputs, dim=1)\n",
        "            correct_predictions += (predicted == targets).sum().item()\n",
        "            total_predictions += targets.size(0)\n",
        "\n",
        "        accuracy = (correct_predictions / total_predictions) * 100\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "train_transformer(transformer_model, train_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4FW78Go1kip",
        "outputId": "8d78ad0f-99f3-4439-c00c-592b66a4220f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.8281, Accuracy: 57.00%\n",
            "Epoch 2, Loss: 0.5733, Accuracy: 71.00%\n",
            "Epoch 3, Loss: 0.3998, Accuracy: 90.00%\n",
            "Epoch 4, Loss: 0.1400, Accuracy: 94.00%\n",
            "Epoch 5, Loss: 0.0164, Accuracy: 100.00%\n",
            "Epoch 6, Loss: 0.0040, Accuracy: 100.00%\n",
            "Epoch 7, Loss: 0.0018, Accuracy: 100.00%\n",
            "Epoch 8, Loss: 0.0011, Accuracy: 100.00%\n",
            "Epoch 9, Loss: 0.0008, Accuracy: 100.00%\n",
            "Epoch 10, Loss: 0.0006, Accuracy: 100.00%\n",
            "Epoch 1, Loss: 1.4472, Accuracy: 61.00%\n",
            "Epoch 2, Loss: 0.6418, Accuracy: 71.00%\n",
            "Epoch 3, Loss: 0.6111, Accuracy: 71.00%\n",
            "Epoch 4, Loss: 0.6020, Accuracy: 71.00%\n",
            "Epoch 5, Loss: 0.3273, Accuracy: 88.00%\n",
            "Epoch 6, Loss: 0.0522, Accuracy: 100.00%\n",
            "Epoch 7, Loss: 0.0158, Accuracy: 100.00%\n",
            "Epoch 8, Loss: 0.0057, Accuracy: 100.00%\n",
            "Epoch 9, Loss: 0.0040, Accuracy: 100.00%\n",
            "Epoch 10, Loss: 0.0026, Accuracy: 100.00%\n"
          ]
        }
      ]
    }
  ]
}